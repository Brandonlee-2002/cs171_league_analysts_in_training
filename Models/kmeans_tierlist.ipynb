{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bac33e-f4f5-41df-8c7d-df67a9b66206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse, os, subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "\n",
    "\n",
    "TIERS_5 = [\"S\",\"A\",\"B\",\"C\",\"D\"]\n",
    "TIERS_6 = [\"S\",\"A\",\"B\",\"C\",\"D\",\"E\"]\n",
    "TIERS_7 = [\"S\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "\n",
    "def logit_percent(p, eps=1e-4):\n",
    "    # p is in % (0..100). Convert to logit in R.\n",
    "    p = np.clip(p / 100.0, eps, 1 - eps)\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "def choose_tier_labels(k):\n",
    "    if k == 5: return TIERS_5\n",
    "    if k == 6: return TIERS_6\n",
    "    if k == 7: return TIERS_7\n",
    "    # fallback: T1..Tk (T1 = best)\n",
    "    return [f\"T{i}\" for i in range(1, k+1)]\n",
    "\n",
    "def rank_clusters_by_center(centers_raw_pct, weights=(0.6, 0.3, 0.1)):\n",
    "    \"\"\"\n",
    "    Rank clusters by a composite score computed in **raw % space** (WR, PR, BR).\n",
    "    centers_raw_pct: array shape (k, 3) for [wr%, pr%, br%]\n",
    "    \"\"\"\n",
    "    w_wr, w_pr, w_br = weights\n",
    "    scores = w_wr*centers_raw_pct[:,0] + w_pr*centers_raw_pct[:,1] + w_br*centers_raw_pct[:,2]\n",
    "    order = np.argsort(-scores)  # descending\n",
    "    rank_of_cluster = np.empty_like(order)\n",
    "    rank_of_cluster[order] = np.arange(len(order))  # 0 = best\n",
    "    return rank_of_cluster, scores\n",
    "\n",
    "def cluster_one_patch(df_patch, k, use_logit=False, weight_by_games=True, random_state=42):\n",
    "    \"\"\"\n",
    "    df_patch columns: championId, championName, win_rate, pick_rate, ban_rate, games\n",
    "    Returns: per-row labels, tier letters, centers (raw %) and mapping.\n",
    "    \"\"\"\n",
    "    feats = df_patch[[\"win_rate\",\"pick_rate\",\"ban_rate\"]].to_numpy(dtype=float)\n",
    "    # Keep a copy in % space for center back-transform\n",
    "    feats_pct = feats.copy()\n",
    "\n",
    "    # Optional transform then scale\n",
    "    if use_logit:\n",
    "        feats = np.column_stack([logit_percent(df_patch[\"win_rate\"].values),\n",
    "                                 logit_percent(df_patch[\"pick_rate\"].values),\n",
    "                                 logit_percent(df_patch[\"ban_rate\"].values)])\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(feats)\n",
    "\n",
    "    # Sample weights (downweight low-sample champs)\n",
    "    sample_weight = None\n",
    "    if weight_by_games and \"games\" in df_patch.columns:\n",
    "        # sqrt or log1p temper extremes; choose one:\n",
    "        sample_weight = np.sqrt(np.clip(df_patch[\"games\"].values, 1, None))\n",
    "        # sample_weight = np.log1p(df_patch[\"games\"].values)\n",
    "\n",
    "    # KMeans\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=random_state)\n",
    "    km.fit(X, sample_weight=sample_weight)\n",
    "    labels = km.labels_\n",
    "\n",
    "    # Compute cluster centers back in **raw %** units (for ranking)\n",
    "    centers_in_feat_space = scaler.inverse_transform(km.cluster_centers_)\n",
    "    if use_logit:\n",
    "        # inverse-logit to %: sigmoid(x)*100\n",
    "        sigmoid = lambda z: 1.0/(1.0+np.exp(-z))\n",
    "        centers_raw_pct = sigmoid(centers_in_feat_space) * 100.0\n",
    "    else:\n",
    "        centers_raw_pct = centers_in_feat_space  # already roughly in % units\n",
    "\n",
    "    # Rank clusters -> tiers\n",
    "    rank_of_cluster, scores = rank_clusters_by_center(centers_raw_pct)\n",
    "    tiers = choose_tier_labels(k)\n",
    "    cluster_to_tier = {c: tiers[rank_of_cluster[c]] for c in range(k)}\n",
    "\n",
    "    return labels, cluster_to_tier, centers_raw_pct, scores\n",
    "\n",
    "def run_for_patch(df, patch, k, use_logit, weight_by_games, out_dir):\n",
    "    dfp = df[df[\"patch\"] == patch].copy()\n",
    "    if dfp.empty:\n",
    "        print(f\"[skip] patch {patch}: no rows\")\n",
    "        return None, None\n",
    "\n",
    "    labels, c2t, centers_raw_pct, scores = cluster_one_patch(\n",
    "        dfp, k=k, use_logit=use_logit, weight_by_games=weight_by_games\n",
    "    )\n",
    "    dfp[\"cluster\"] = labels\n",
    "    dfp[\"tier\"] = dfp[\"cluster\"].map(c2t)\n",
    "\n",
    "    # Save tier list\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_csv = out_dir / f\"tierlist_patch_{patch}.csv\"\n",
    "    cols = [\"patch\",\"championId\",\"championName\",\"win_rate\",\"pick_rate\",\"ban_rate\",\"games\",\"cluster\",\"tier\"]\n",
    "    dfp[cols].to_csv(out_csv, index=False)\n",
    "    print(f\"[saved] {out_csv}\")\n",
    "\n",
    "    # Save cluster centers\n",
    "    centers_df = pd.DataFrame(centers_raw_pct, columns=[\"center_wr_pct\",\"center_pr_pct\",\"center_br_pct\"])\n",
    "    centers_df[\"cluster\"] = np.arange(len(centers_df))\n",
    "    centers_df[\"score\"] = scores\n",
    "    centers_df[\"tier\"] = centers_df[\"cluster\"].map(c2t)\n",
    "    centers_df[\"patch\"] = patch\n",
    "    centers_csv = out_dir / f\"tier_centers_patch_{patch}.csv\"\n",
    "    centers_df[[\"patch\",\"cluster\",\"tier\",\"center_wr_pct\",\"center_pr_pct\",\"center_br_pct\",\"score\"]].to_csv(centers_csv, index=False)\n",
    "    print(f\"[saved] {centers_csv}\")\n",
    "\n",
    "    return dfp, centers_df\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"K-means tier list from WR/PR/BR (per patch)\")\n",
    "    ap.add_argument(\"--csv\", required=True, help=\"Input CSV with columns: patch, championId, championName, win_rate, pick_rate, ban_rate, games\")\n",
    "    ap.add_argument(\"--k\", type=int, default=5, help=\"Number of tiers/clusters (default 5)\")\n",
    "    ap.add_argument(\"--patch\", default=None, help=\"Specific patch (e.g., '15.22'). If omitted and --each not set, uses latest.\")\n",
    "    ap.add_argument(\"--each\", action=\"store_true\", help=\"Cluster each patch separately and save multiple tierlists\")\n",
    "    ap.add_argument(\"--logit\", action=\"store_true\", help=\"Use logit transform on rates before scaling (often better)\")\n",
    "    ap.add_argument(\"--no-weight\", action=\"store_true\", help=\"Disable games-based sample weighting\")\n",
    "    ap.add_argument(\"--out-dir\", default=os.path.expanduser(\"~/riot_out/tierlists\"))\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    SCRIPT_DIR = Path(__file__).resolve().parent\n",
    "    def git_root(start: Path) -> Path | None:\n",
    "        try:\n",
    "            p = subprocess.check_output(\n",
    "                [\"git\", \"rev-parse\", \"--show-toplevel\"],\n",
    "                cwd=start\n",
    "            ).decode().strip()\n",
    "            return Path(p)\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    REPO_ROOT = git_root(SCRIPT_DIR)\n",
    "\n",
    "    out_dir = Path(os.getenv(\"out_dir\", REPO_ROOT / \"riot_out\"))\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"[out] saving to: {out_dir}\")\n",
    "    df = pd.read_csv(args.csv, dtype={\"patch\": str})  # preserve \"15.20\"\n",
    "\n",
    "    print(f\"[debug] loaded rows: {len(df)} from {args.csv}\")\n",
    "\n",
    "    # 1) normalize patch â†’ \"major.minor\"\n",
    "    def canon_patch(p):\n",
    "        s = str(p).strip()\n",
    "        m = re.search(r'(\\d+)\\.(\\d+)', s)\n",
    "        return f\"{int(m.group(1))}.{int(m.group(2))}\" if m else None\n",
    "    df[\"patch\"] = df[\"patch\"].map(canon_patch)\n",
    "\n",
    "    # 2) ensure required columns exist\n",
    "    if \"ban_rate\" not in df.columns:\n",
    "        df[\"ban_rate\"] = 0.0\n",
    "    if \"games\" not in df.columns:\n",
    "        df[\"games\"] = 1\n",
    "\n",
    "    # 3) numeric coercion\n",
    "    for c in [\"win_rate\",\"pick_rate\",\"ban_rate\",\"games\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # 4) drop rows that can't be used\n",
    "    df = df.dropna(subset=[\"patch\",\"win_rate\",\"pick_rate\",\"ban_rate\",\"games\"]).copy()\n",
    "\n",
    "    # 5) show which patches remain\n",
    "    # 3) when picking the latest patch, sort NUMERICALLY\n",
    "    patches = sorted(df[\"patch\"].unique(), key=lambda p: tuple(map(int, p.split(\".\"))))\n",
    "    # if --patch not provided, choose the max numerically:\n",
    "    target_patch = args.patch or patches[-1]\n",
    "    print(\"[debug] patches after cleaning:\", patches)\n",
    "    print(\"[debug] counts by patch:\\n\", df[\"patch\"].value_counts().sort_index())\n",
    "\n",
    "    if args.each:\n",
    "        all_rows, all_centers = [], []\n",
    "        for p in patches:\n",
    "            res = run_for_patch(df, p, args.k, args.logit, not args.no_weight, out_dir)\n",
    "            if res[0] is not None:\n",
    "                all_rows.append(res[0]); all_centers.append(res[1])\n",
    "        if all_rows:\n",
    "            pd.concat(all_rows).to_csv(out_dir / \"tierlist_all_patches.csv\", index=False)\n",
    "            pd.concat(all_centers).to_csv(out_dir / \"tier_centers_all_patches.csv\", index=False)\n",
    "            print(f\"[saved] {out_dir/'tierlist_all_patches.csv'}\")\n",
    "            print(f\"[saved] {out_dir/'tier_centers_all_patches.csv'}\")\n",
    "        pass\n",
    "    else:\n",
    "        target_patch = canon_patch(args.patch) if args.patch else patches[-1]\n",
    "        run_for_patch(df, target_patch, args.k, args.logit, not args.no_weight, out_dir)\n",
    "        print(\"[debug] selecting patch:\", target_patch)\n",
    "        run_for_patch(df, target_patch, args.k, args.logit, not args.no_weight, out_dir)\n",
    "        return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
