{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tierlist Scraper"
      ],
      "metadata": {
        "id": "9JLy0L5XGNbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The functions below work on lolalytics html files.\n",
        "2. The lolalytics html files must be located in the same folder as the notebook.\n",
        "3. It outputs csv functions in the same folder as the notebook."
      ],
      "metadata": {
        "id": "JNCoK-ue9lip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_champ_names():\n",
        "  # Read HTML content from a file\n",
        "  with open(\"LoL Tier List - LoLalytics LoL Tier List for Patch 15.13.html\", 'r', encoding='utf-8') as file:\n",
        "      html_cont = file.read()\n",
        "\n",
        "  # Parse the HTML content\n",
        "  soup = BeautifulSoup(html_cont, 'html.parser')\n",
        "\n",
        "  # Extract text from all tags\n",
        "  all_tags = soup.find_all()\n",
        "\n",
        "  # find index position of champion data.\n",
        "  endtierlist = \"LoLalytics isn't endorsed by Riot Games and doesn't reflect the views\"\n",
        "  tierlistflag = False\n",
        "  patch_tierlist_data = []\n",
        "  for n, tag in enumerate(all_tags):\n",
        "      if tag.get_text() == 'Elo':\n",
        "        tierlistflag = True\n",
        "      elif endtierlist in tag.get_text():\n",
        "        tierlistflag = False\n",
        "      elif tag.get_text() != '' and tierlistflag:\n",
        "        patch_tierlist_data.append(tag.get_text())\n",
        "\n",
        "  # get a list of champions to make it easier to parse through data later.\n",
        "  champ_names = set()\n",
        "  for n, line in enumerate(patch_tierlist_data[6::28]):\n",
        "    if n <= 56:\n",
        "      #print(n, line)\n",
        "      champ_names.add(line)\n",
        "  for n, line in enumerate(patch_tierlist_data[10::28]):\n",
        "    if n > 56:\n",
        "      #print(n, line)\n",
        "      champ_names.add(line)\n",
        "  champ_names.add('Yunara') # add yunara as she is not in this patch\n",
        "  return champ_names\n",
        "champ_names = get_champ_names()\n",
        "len(champ_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvP8sKIJtx9i",
        "outputId": "f99d68fd-dde3-4b34-ffba-150624c2d660"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "171"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(patch, champ_names):\n",
        "# Read HTML content from a file\n",
        "  with open(f\"LoL Tier List - LoLalytics LoL Tier List for Patch {patch}.html\", 'r', encoding='utf-8') as file:\n",
        "    html_cont = file.read()\n",
        "  # Parse the HTML content\n",
        "  soup = BeautifulSoup(html_cont, 'html.parser')\n",
        "  # Extract text from all tags\n",
        "  all_tags = soup.find_all()\n",
        "\n",
        "\n",
        "  # reduce the html tags to only the champion tier list\n",
        "  endtierlist = \"LoLalytics isn't endorsed by Riot Games and doesn't reflect the views\"\n",
        "  tierlistflag = False\n",
        "  patch_tierlist_data = []\n",
        "  for n, tag in enumerate(all_tags):\n",
        "    if tag.get_text() == 'Elo':\n",
        "      tierlistflag = True\n",
        "    elif endtierlist in tag.get_text():\n",
        "      tierlistflag = False\n",
        "    elif tag.get_text() != '' and tierlistflag:\n",
        "      patch_tierlist_data.append(tag.get_text())\n",
        "\n",
        "\n",
        "  # make a dictionary of empty lists\n",
        "  champ_data_dict = {}\n",
        "  # append data to champions in a dictorionary\n",
        "  champ_flag = 'z'\n",
        "  # append numerical data from patch data to a dictionary\n",
        "  for line in patch_tierlist_data:\n",
        "    if line in champ_names:\n",
        "      champ_flag = line\n",
        "    # add champions sequentially to dictionary to preserve rank order\n",
        "    if not(champ_flag in champ_data_dict.keys()) and champ_flag in champ_names:\n",
        "      champ_data_dict[champ_flag] = []\n",
        "    # set lines that can turn into floats into the dictionary for further parsing\n",
        "    if champ_flag in champ_data_dict.keys():\n",
        "      try:\n",
        "        line = float(line)\n",
        "        champ_data_dict[champ_flag].append(line)\n",
        "      except: continue\n",
        "\n",
        "\n",
        "  # select proper values, all decimals in percentages\n",
        "  champ_rates = {\n",
        "      'patch':[],\n",
        "      'champion':[],\n",
        "      'win_rate':[],\n",
        "      'pick_rate':[],\n",
        "      'ban_rate':[],\n",
        "      'rank':[],\n",
        "  }\n",
        "  for n, key in enumerate(champ_data_dict.keys()):\n",
        "    if len(champ_data_dict[key]) > 0: # in case yunara isn't in the patch\n",
        "      #if champ_data_dict[key][2] > 52:\n",
        "      #  print(f'{n+1} {key}: \\nWinRate:{champ_data_dict[key][2]} PickRate:{champ_data_dict[key][5]} BanRate:{champ_data_dict[key][6]}\\n')\n",
        "      champ_rates['patch'].append(patch)\n",
        "      champ_rates['champion'].append(key)\n",
        "      champ_rates['win_rate'].append(champ_data_dict[key][2])\n",
        "      champ_rates['pick_rate'].append(champ_data_dict[key][5])\n",
        "      champ_rates['ban_rate'].append(champ_data_dict[key][6])\n",
        "      champ_rates['rank'].append(n+1)\n",
        "\n",
        "  pd.DataFrame(champ_rates).to_csv(f'lolpatch_{patch}.csv', index=False)"
      ],
      "metadata": {
        "id": "M_sB9-nAgdHo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the scraper for patches 13 through 20\n",
        "for patch in range(13,21):\n",
        "  patch = f'15.{patch}'\n",
        "  parse_data(patch,champ_names)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wwi3u_WE6ceC"
      },
      "execution_count": 3,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}